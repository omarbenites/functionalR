---
title: "Boost Statistical Computing through Functional Programming in R"
author: Omar Benites
output:
  html_document: 
    toc: yes
  html_notebook: default
---

```{r,echo=FALSE}
  knitr::clean_cache()

```

# Module 1: Introduction

Almost everything in R is based on functions or functional-approach programming. A function is a piece of code that we usually run in our analysis that are compresed in a expresed that can be re-used.

A function is compouned by:

- **Name of the function**: To put a function name you need the assignment operator  **<-**.  
- **The arguments** (formal argumentes) of the function. Could be whatever type of data structure.
- **The body**: for what the function is composed.
- **The environment**: it's the environment where the environment is defined. By the default is the global environment. This is imporntant because it is where the function looks for variables, this is called the *scope* of the function.


```{r, echo=TRUE, eval=TRUE}
add <- function(x,y = 1){
        x+y
}
##
formals(add)
body(add)
environment(add)
```

One important things that is the *return* command. If we use *return*, automatically the function answers with the result and then stop. For example


```{r, echo=TRUE, eval=TRUE}
minor <- function(x, y){
      r <- x-y #local variable r
      return(r)
      1+1
}

minor(x = 15, y =12)

```


Function are also objects. For example if we assign the function *mean* to new variable, it looks like:


```{r, echo=TRUE, eval=TRUE}
mean2 <- mean
v <- c(15, 12)
mean2(v)
```


# Environments 

## Scoping of R-functions

Scoping describes how R looks up values by name. For example

```{r, echo=TRUE, eval=TRUE}
f <- function() {
 x <- 1
 y <- 2
 c(x, y)
}
f()
```

In this case, the function *f* looks for the values which are inside the function. However exists another cases where the function looks for one level up. Let see:

```{r, echo=TRUE, eval=TRUE}
z <- 15
f <- function() {
 x <- 1
 y <- 2
 c(x, y, z)
}
f()
```
In this case, the function does not define **z** in their scope. As a consequence, the funcion searchs outside the function's environment (or local environment) and goes one level up and catch *z* in the global environment. In case *z* is defined it clearly show the output *(1 ,2 ,15)*, otherwise it prints an error. For example (uncomment to see the mistake):

```{r, echo=TRUE, eval=TRUE}
# z <- 15
# f <- function() {
#  x <- 1
#  y <- 2
#  c(x, y, z, d)
# }
# f()
```

See that variable **d** is not defined in the local or global environment. For this reason, it shows an error as follow: *Error in f() : object 'd' not found*.

Okay, now I open a new question: What happen wheter a variable is defined inside and outside the function scope?. Let see

```{r, echo=TRUE, eval=TRUE}
z <- 15
producto <- function(z) {
 z <- 1
 y <- 2
 z*y
}
producto()
```
The answer is simple, the function prioritize the local variable over the global variable.


# Module 2:  Functional Programming (FP)

Several times we work with repeated procedures that need to be automatized. In order to do this, we requiere the use **for** loops. The **For** loop is a finite repeated procedure to couldn't help write the same pice of code for different values. An example as following:

- Calculation of the media **col_media** 

```{r, echo=TRUE, eval=TRUE}
#The st4gi library
library(st4gi)
#By now, we are going to extract the first two dull columns.
df <- pjpz09[,-c(1:2)]
#The pre-allocation of 'med' variable that storage the medians for each column or trait
col_media <- vector("numeric", length = ncol(df))
#A second option is using: 
#seq_along is the same as write  'i in 1:length(col_media)' 
for(i in seq_along(col_media) ){
  col_media[i] <- mean(df[[i]])
  #col_media[i] <- mean(df[,i])
}
col_media
```


- Calculation of the median **col_mediana** 

```{r, echo=TRUE, eval=TRUE}
#The st4gi library
library(st4gi)
df <- pjpz09[,-c(1:2)]
col_mediana <- vector("numeric", length = ncol(df))
for(i in seq_along(col_mediana) ){
  col_mediana[i] <- median(df[[i]])
}
col_mediana
```

- Finally the standard deviation **col_devs**

```{r, echo=TRUE, eval=TRUE}
#The st4gi library
library(st4gi)
df <- pjpz09[,-c(1:2)]
col_devs <- vector("numeric", length = ncol(df))
for(i in seq_along(col_devs) ){
  col_devs[i] <- sd(df[[i]])
}
col_devs
```

As we can see, the for loop help us to calculate iteratively the mean, median and s.deviation for different *i* columns. However a new question arises based on this examples: *How about iterate functions and not only values?*.  Following the first question derives the second one, *Functions could be arguments of other functions?*

To elucidate these doubts, we are going to pass a function as argument of other function called **col_summary**. **col_summary** has two arguments **df** and **fun**, where *df* is the data and *fun* is a function argument.

```{r, echo=TRUE, eval=TRUE}
library(st4gi)
df <- pjpz09[,-c(1:2)]

col_summary <- function(df, fun) {
    #Second way to pre-allocate, using numeric(length(vector or dataframe))  
    output <- numeric(length(df))
    for (i in seq_along(df)) {
        output[i] <- fun(df[[i]])
    }
    output
}
#Let make some calculations over the columns using the mean, median and standard desviation
col_summary(df, fun = mean)
col_summary(df, fun = median)
col_summary(df, fun = sd)
```

It is plain to see that a function can be an argument of other function. Note that the *fun* argument is used without double quotes. 

The R-base program provides function which use the functional programming approach. The set of function of this family are: apply, sapply, rapply, etc. Lets review an example:

```{r, echo=TRUE, eval=TRUE}
### Using sapply function ###
library(st4gi)
df <- pjpz09[,-c(1:2)]
sapply(df, mean)
```

```{r, echo=TRUE, eval=TRUE}
### Using our implentation
col_summary(df, fun = mean)
```


Along the year, many r-packages has rised and one of them tackle the functional programming approach, this is the **purrr** package from Hadley Wickham. **purr** package (written with three *r*s similarly to cat's meowth) provides a robust implementation of the FP paradigm in R. Besides, it wrapps *C++* code to make the computing much more faster when you are dealing with big datasets or the famous *Big Data*.


## The purrr package

To begin with *purrr* package, we will use the set of *map* functions. For example, lets calculate the mean over all traits using *purr*

```{r, echo=TRUE, eval=TRUE, warning=FALSE}
library(purrr)
map_dbl(.x = df, .f= mean)
```

What `purrr` basically does is:

1. Loop over a vector `.x`. More generally, `.x` could be a data structue as vectors, data frames, lists, etc.

2. Do something to each element `.f`. For instance, it pass the mean function over all the data structure.

3. Return the results.


The `map` function varies in their return type. Here the complete list:

- ``map()`` returns a list. You can pass complex function as summary, etc.
- ``map_dbl()`` returns a double vector
- ``map_lgl()`` returns a logical vector
- ``map_int()`` returns a integer vector
- ``map_chr()`` returns a character vector

The map functions use the `...`  (*dot dot dot*) argument to pass along additional arguments to `.f` each time itâ€™s called. For example, we can pass the trim argument to the `mean()` function:

```{r, echo=TRUE, eval=TRUE,warning=FALSE}
map_dbl(df, mean, trim = 0.5)
```

Multiple arguments can be passed along using commas to separate them. For example, we can also pass the na.rm argument to mean():

```{r, echo=TRUE, eval=TRUE,warning=FALSE}
map_dbl(df, mean, trim = 0.5, na.rm = TRUE)
```


Do you notice somthing weird about `map` arguments?. Yes, you don't have to specify the arguments by name (or double quoted arguments), but it is good practice!


You may be wondering why the arguments to `map()` are `.x` and `.f` and not `x` and `f`? It's because `.x` and `.f` are very unlikely to be argument names you might pass through the `...`, thereby preventing confusion about whether an argument belongs to `map()` or to the function being mapped.

Now we are going to use the `cropdatape` dataset

```{r, echo=TRUE, eval=TRUE,warning=FALSE,message=FALSE}
library(cropdatape)
library(dplyr)
dtrice <- cropdatape %>% filter(crop == "rice") %>% select(-crop,-department,-year,-month ) 
map_dbl(dtrice, mean, trim = 0.5, na.rm = TRUE)
```



## Picking the right map function

Choosing the right function is important. If you know beforehand what is the expected output of the function that you pass to `map` functions, make better the task of using each type of `map` function. Lets see a example:


- To find the columns that are numeric we use `is.numeric()`, which returns logical values `TRUE` or `FALSE`. For this reason, we utilize `map_lgl` due to allow logical outputs.

```{r, echo=TRUE, eval=TRUE,warning=FALSE,message=FALSE}
map_lgl(cropdatape, is.numeric)
```

- To find the type of each columns we use `class()`, which returns character values, for instance, `character`, `numeric`, `logical`, `list`. For this reason, we utilize `map_chr` as long as the called function gives back characters.


```{r, echo=TRUE, eval=TRUE,warning=FALSE,message=FALSE}
map_chr(cropdatape, class)
```

- To find a summary of each column we utilize `summary()`. In contrast with examples before, we are going to handle the function `map`. `map` concede more complex functions as `summary`, `str`, among others. 


```{r, echo=TRUE, eval=TRUE,warning=FALSE,message=FALSE}
map(cropdatape, summary)
```


## Specifying Functions (.f)

Until now, all the functions are defined by R-libraries. However, in the vast majority of cases users can define their own functions. Let see an example:

```{r, echo=TRUE, eval=TRUE,warning=FALSE,message=FALSE}
map(cropdatape, function(x) sum(is.na(x)))
```


In this case, `function(x)sum(is.na(x))` is called, in functional programming, **Anonymous Function**.


Additionally, another way to pass user-defined functions is using a formular short-cut. Here an example:


```{r, echo=TRUE, eval=TRUE,warning=FALSE,message=FALSE}
map(cropdatape, ~ sum(is.na(.)))
```


## Shortcuts when f is [[

Let's create a list of varieties of two crops, potato and sweet potato, called `list_of_var`.

```{r, echo=TRUE, eval=TRUE,warning=FALSE,message=FALSE}
 list_of_var <- list(
          list(potato= "amarilla" , sweetpotato = "jonathan"),
          list(potato= "huayro" , sweetpotato = "tacna"),
          list(potato= "tomasa" , sweetpotato = "huambachero")
 )
```

- Using anonymous function

```{r, echo=TRUE, eval=TRUE,warning=FALSE,message=FALSE}
map_chr(list_of_var, function(x) x[["potato"]])
map_chr(list_of_var, function(x) x[["sweetpotato"]])
```

- Using directly the name (a) (item list)

```{r, echo=TRUE, eval=TRUE,warning=FALSE,message=FALSE}
map_chr(list_of_var, "potato")
map_chr(list_of_var, "sweetpotato")
```

- Using the position of the item list (the first element is (a), the second is (b))

```{r, echo=TRUE, eval=TRUE,warning=FALSE,message=FALSE}
map_chr(list_of_var, 1)
map_chr(list_of_var, 2)
```


## A list of data.frames

In R, it possible to generate  a list of tiny data frames based on big data frame. For instance, we use the `split` function:

```{r, echo=TRUE, eval=TRUE,warning=FALSE,message=FALSE}
crops <- split(cropdatape, cropdatape$crop)
```

- Extract rice tiny data frame
```{r, echo=TRUE, eval=TRUE,warning=FALSE,message=FALSE}
crops$rice
```



Combining the all cases above, we can apply to obtain `R2` from statistical models. We utilize the `mtcars` dataset in this example: 

```{r, echo=TRUE, eval=TRUE,warning=FALSE,message=FALSE}
# Define models (don't change)
models <- mtcars %>% 
  split(mtcars$cyl) %>%
  map(~ lm(mpg ~ wt, data = .))
models
```

```{r, echo=TRUE, eval=TRUE,warning=FALSE,message=FALSE}
summaries <- map(models, summary) %>% 
             map_dbl(., "r.squared")
summaries
```







#Bibiliografia

- Ingles: http://menuaingles.blogspot.pe/2012/09/as-soon-as-as-long-as-as-far-as.html
